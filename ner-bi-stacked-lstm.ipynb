{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ner_dataset.csv', 'ner.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "import tensorflow as tf\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 281837: expected 25 fields, saw 34\\n'\n"
     ]
    }
   ],
   "source": [
    "dframe = pd.read_csv(\"../input/ner.csv\", encoding = \"ISO-8859-1\", error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>lemma</th>\n",
       "      <th>next-lemma</th>\n",
       "      <th>next-next-lemma</th>\n",
       "      <th>next-next-pos</th>\n",
       "      <th>next-next-shape</th>\n",
       "      <th>next-next-word</th>\n",
       "      <th>next-pos</th>\n",
       "      <th>next-shape</th>\n",
       "      <th>next-word</th>\n",
       "      <th>pos</th>\n",
       "      <th>prev-iob</th>\n",
       "      <th>prev-lemma</th>\n",
       "      <th>prev-pos</th>\n",
       "      <th>prev-prev-iob</th>\n",
       "      <th>prev-prev-lemma</th>\n",
       "      <th>prev-prev-pos</th>\n",
       "      <th>prev-prev-shape</th>\n",
       "      <th>prev-prev-word</th>\n",
       "      <th>prev-shape</th>\n",
       "      <th>prev-word</th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>shape</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>thousand</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>NNS</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>NNS</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>__start1__</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>__start2__</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>wildcard</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>wildcard</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>1.0</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>NNS</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>thousand</td>\n",
       "      <td>NNS</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>__start1__</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>wildcard</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>have</td>\n",
       "      <td>march</td>\n",
       "      <td>VBN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBP</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>thousand</td>\n",
       "      <td>NNS</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>have</td>\n",
       "      <td>march</td>\n",
       "      <td>through</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>through</td>\n",
       "      <td>VBN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>march</td>\n",
       "      <td>through</td>\n",
       "      <td>london</td>\n",
       "      <td>NNP</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>London</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>through</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>NNS</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     lemma next-lemma ...        shape           word tag\n",
       "0           0  thousand         of ...  capitalized      Thousands   O\n",
       "1           1        of   demonstr ...    lowercase             of   O\n",
       "2           2  demonstr       have ...    lowercase  demonstrators   O\n",
       "3           3      have      march ...    lowercase           have   O\n",
       "4           4     march    through ...    lowercase        marched   O\n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=dframe[['word','tag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "tag=[]\n",
    "x=[]\n",
    "y=[]\n",
    "for k,v in zip(df1.word,df1.tag):\n",
    "    \n",
    "    if k==\".\":\n",
    "        data.append(x)\n",
    "        tag.append(y)\n",
    "        x=[]\n",
    "        y=[]\n",
    "    else:\n",
    "        x.append(k)\n",
    "        y.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47895"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[:20000]\n",
    "tag=tag[:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen=max(map(len,data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter,defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadict=defaultdict(lambda:0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_data_words=set()\n",
    "for x in data:\n",
    "    uniq_data_words.update(set(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = ['<UNK>', '<PAD>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=special_tokens+list(x for x in uniq_data_words if x not in special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_tags=set()\n",
    "for x in tag:\n",
    "    uniq_tags.update(set(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tags=['<PAD>']+list(uniq_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_2_indx=dict([(v,k) for k,v in enumerate(words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_2_token=dict([(v,k) for k,v in tok_2_indx.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_2_indx=dict([(k,v) for v,k in enumerate(unique_tags)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx_2_tag=dict([(k,v) for v,k in tag_2_indx.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(data,tag,batchsize,shuffle=True,allow_smaller_lastbatch=True):\n",
    "    N=len(data)\n",
    "    if shuffle==True:\n",
    "        order=np.random.permutation(N)\n",
    "    else:\n",
    "        order=np.arange(N)\n",
    "        \n",
    "    n_batches=N//batchsize\n",
    "    if allow_smaller_lastbatch and (N%batchsize):\n",
    "        n_batches+=1\n",
    "        \n",
    "    for k in range(n_batches):\n",
    "        batchstart=k*batchsize\n",
    "        batchend=min(batchstart+batchsize,N)\n",
    "        \n",
    "        currentbatchsize=batchend-batchstart\n",
    "        \n",
    "        x_list=[]\n",
    "        y_list=[]\n",
    "        \n",
    "        max_len_token=0\n",
    "        \n",
    "        for idx in order[batchstart:batchend]:\n",
    "            x_list.append([tok_2_indx[i] for i in data[idx]])\n",
    "            y_list.append([tag_2_indx[i] for i in tag[idx]])\n",
    "            \n",
    "            max_len_token=max(max_len_token,len(data[idx]))\n",
    "        \n",
    "        x=np.ones([currentbatchsize,max_len_token],dtype=np.int32)*tok_2_indx['<PAD>']\n",
    "        y=np.ones([currentbatchsize,max_len_token],dtype=np.int32)*tag_2_indx['<PAD>']\n",
    "        \n",
    "        lengths=np.zeros(currentbatchsize,dtype=np.int32)\n",
    "        \n",
    "        for n in range(currentbatchsize):\n",
    "            len1=len(x_list[n])\n",
    "            x[n,:len1]=x_list[n]\n",
    "            y[n,:len1]=y_list[n]\n",
    "            \n",
    "            lengths[n]=len1\n",
    "        \n",
    "        yield x,y,lengths\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.placeholder(dtype=tf.int32,shape=[None,None])\n",
    "y=tf.placeholder(dtype=tf.int32,shape=[None,None])\n",
    "lengths=tf.placeholder(dtype=tf.int32,shape=[None])\n",
    "drpout=tf.placeholder(dtype=tf.float32,shape=[])\n",
    "lr=tf.placeholder(dtype=tf.float32,shape=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "enc_var=tf.Variable(tf.random_normal(shape=[len(tok_2_indx),32]),dtype=tf.float32)\n",
    "encod_emb=tf.nn.embedding_lookup(enc_var,x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createcell():\n",
    "    cell=tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.LSTMCell(256),input_keep_prob=drpout,output_keep_prob=drpout)\n",
    "    return cell\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlayers=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-24-095e5254eee8>:2: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    }
   ],
   "source": [
    "cellfw=[createcell() for i in range(nlayers)]\n",
    "cellbw=[createcell() for i in range(nlayers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/contrib/rnn/python/ops/rnn.py:233: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "outputs,outputlast_fw,outputlast_bw=tf.contrib.rnn.stack_bidirectional_dynamic_rnn(cellfw,cellbw,encod_emb,sequence_length=lengths,dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'stack_bidirectional_rnn/cell_1/concat:0' shape=(?, ?, 512) dtype=float32>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-29-ed8a1436150e>:1: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n"
     ]
    }
   ],
   "source": [
    "logits=tf.layers.dense(outputs,len(tag_2_indx),activation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_softmax=tf.nn.softmax(logits,axis=-1)\n",
    "pred=tf.argmax(pred_softmax,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-31-f3a5337cc220>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ytruth=tf.one_hot(y,len(tag_2_indx))\n",
    "loss=tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=ytruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=tf.cast(tf.not_equal(x,tok_2_indx['<PAD>']),tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1=tf.reduce_mean(tf.multiply(loss,mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=tf.train.AdamOptimizer(learning_rate=lr)\n",
    "grads_vars=optimizer.compute_gradients(loss1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_norm=tf.cast(1.0,tf.float32)\n",
    "grads_vars1=[(tf.clip_by_norm(grad,1.0),var) for grad,var in grads_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_op=optimizer.apply_gradients(grads_vars1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize=32\n",
    "epochs=5\n",
    "lr1=0.006\n",
    "lr_decay=2**(0.5)\n",
    "drp=0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count:- 0  training loss:- 1.5411783\n",
      "count:- 50  training loss:- 0.45688027\n",
      "count:- 100  training loss:- 0.29421812\n",
      "count:- 150  training loss:- 0.22619155\n",
      "count:- 200  training loss:- 0.19595589\n",
      "count:- 250  training loss:- 0.1351361\n",
      "count:- 300  training loss:- 0.12707186\n",
      "count:- 350  training loss:- 0.07325581\n",
      "count:- 400  training loss:- 0.12885165\n",
      "count:- 450  training loss:- 0.10154069\n",
      "count:- 500  training loss:- 0.11342144\n",
      "count:- 550  training loss:- 0.14052346\n",
      "count:- 600  training loss:- 0.11057894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [02:33<10:15, 153.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count:- 0  training loss:- 0.052858345\n",
      "count:- 50  training loss:- 0.05651643\n",
      "count:- 100  training loss:- 0.07435864\n",
      "count:- 150  training loss:- 0.06973711\n",
      "count:- 200  training loss:- 0.06430338\n",
      "count:- 250  training loss:- 0.08007337\n",
      "count:- 300  training loss:- 0.13355084\n",
      "count:- 350  training loss:- 0.10281715\n",
      "count:- 400  training loss:- 0.095142655\n",
      "count:- 450  training loss:- 0.09011428\n",
      "count:- 500  training loss:- 0.0996816\n",
      "count:- 550  training loss:- 0.07238927\n",
      "count:- 600  training loss:- 0.06583733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [05:05<07:39, 153.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count:- 0  training loss:- 0.03449443\n",
      "count:- 50  training loss:- 0.07504302\n",
      "count:- 100  training loss:- 0.062063448\n",
      "count:- 150  training loss:- 0.03602847\n",
      "count:- 200  training loss:- 0.029952377\n",
      "count:- 250  training loss:- 0.08442108\n",
      "count:- 300  training loss:- 0.033944476\n",
      "count:- 350  training loss:- 0.058183957\n",
      "count:- 400  training loss:- 0.040421072\n",
      "count:- 450  training loss:- 0.030067042\n",
      "count:- 500  training loss:- 0.03008342\n",
      "count:- 550  training loss:- 0.09494209\n",
      "count:- 600  training loss:- 0.059756268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [07:37<05:05, 152.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count:- 0  training loss:- 0.029217428\n",
      "count:- 50  training loss:- 0.04527338\n",
      "count:- 100  training loss:- 0.052889768\n",
      "count:- 150  training loss:- 0.03936662\n",
      "count:- 200  training loss:- 0.053506248\n",
      "count:- 250  training loss:- 0.039592676\n",
      "count:- 300  training loss:- 0.051703643\n",
      "count:- 350  training loss:- 0.039592955\n",
      "count:- 400  training loss:- 0.04128531\n",
      "count:- 450  training loss:- 0.059131276\n",
      "count:- 500  training loss:- 0.040608663\n",
      "count:- 550  training loss:- 0.053700134\n",
      "count:- 600  training loss:- 0.055432267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [10:07<02:32, 152.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count:- 0  training loss:- 0.01841508\n",
      "count:- 50  training loss:- 0.042483415\n",
      "count:- 100  training loss:- 0.026440684\n",
      "count:- 150  training loss:- 0.033613488\n",
      "count:- 200  training loss:- 0.030196382\n",
      "count:- 250  training loss:- 0.018558629\n",
      "count:- 300  training loss:- 0.018651238\n",
      "count:- 350  training loss:- 0.016063515\n",
      "count:- 400  training loss:- 0.028273921\n",
      "count:- 450  training loss:- 0.010998628\n",
      "count:- 500  training loss:- 0.03356668\n",
      "count:- 550  training loss:- 0.021550514\n",
      "count:- 600  training loss:- 0.024969628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [12:39<00:00, 151.95s/it]\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(epochs)):\n",
    "    count=0\n",
    "    for xbatch,ybatch,lengths1 in batch_generator(data,tag,batchsize):\n",
    "        feeddict={x:xbatch,y:ybatch,lengths:lengths1,drpout:drp,lr:lr1}\n",
    "        _,tloss=sess.run([train_op,loss1],feed_dict=feeddict)\n",
    "        if (count%50)==0:\n",
    "            print(\"count:-\",count ,\" training loss:-\",tloss)\n",
    "        count+=1\n",
    "    lr1=lr1/(lr_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=[[tok_2_indx[i] for i in sent] for sent in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain=[[tag_2_indx[i] for i in tagsent] for tagsent in tag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "len1=[len(sent) for sent in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen=max(len1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "padarray=np.ones([20000,maxlen])*tok_2_indx['<PAD>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "paddtokarray=np.ones([20000,maxlen])*tag_2_indx['<PAD>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(20000):\n",
    "    padarray[i,:len(xtrain[i])]=xtrain[i]\n",
    "    paddtokarray[i,:len(ytrain[i])]=ytrain[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "feeddict={x:padarray,y:paddtokarray,lengths:len1,drpout:1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=sess.run([pred],feed_dict=feeddict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind2tag=dict([(v,k) for k,v in tag_2_indx.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "yactual=[]\n",
    "ypred=[]\n",
    "for i in range(20000):\n",
    "    yactual+=tag[i]\n",
    "    ypred+=[indx_2_tag[j] for j in prediction[0][i][:len1[i]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418914"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yactual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1score=f1_score(ypred,yactual,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9171354062357738"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
